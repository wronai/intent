# ğŸ” IntentForge - Analiza Projektu i Plan Refaktoryzacji

## âŒ Zidentyfikowane Problemy

### 1. Duplikaty PlikÃ³w

| Plik | Lokalizacja 1 | Lokalizacja 2 | Status |
|------|---------------|---------------|--------|
| **JS SDK** | `/sdk/intentforge.js` (730 linii) | `/intentforge/static/js/intentforge-client.js` (364 linie) | âš ï¸ Dwa rÃ³Å¼ne API! |
| **ENV** | `.env.example` | `.env.complete.example` | âš ï¸ Duplikat |
| **Static** | `/static/index.html` | `/intentforge/static/` | âš ï¸ Dwa foldery |

### 2. NiespÃ³jna Struktura FolderÃ³w

```
âŒ PRZED (aktualnie):
intentforge/
â”œâ”€â”€ sdk/                      # SDK oddzielnie
â”œâ”€â”€ static/                   # Frontend root
â”œâ”€â”€ intentforge/
â”‚   â”œâ”€â”€ static/               # âŒ DUPLIKAT
â”‚   â”‚   â””â”€â”€ js/               # âŒ Inny JS client
â”‚   â””â”€â”€ ...
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ example1_*.py
â”‚   â”œâ”€â”€ example2_*.html       # âŒ Mieszanka
â”‚   â”œâ”€â”€ usecases/             # âŒ Podkatalog
â””â”€â”€ config/                   # Tylko mosquitto/nginx
```

### 3. Brak Wsparcia LLM

| Provider | Status | RozwiÄ…zanie |
|----------|--------|-------------|
| Anthropic | âœ… | Wbudowane |
| OpenAI | âœ… | Wbudowane |
| **Ollama** | âŒ Brak | ğŸ†• Dodane w `llm/providers.py` |
| **LiteLLM** | âŒ Brak | ğŸ†• Dodane w `llm/providers.py` |

### 4. BezpieczeÅ„stwo Frontend

| Problem | Ryzyko | Status |
|---------|--------|--------|
| Brak rate limiting | Wysokie | ğŸ†• Naprawione |
| Brak walidacji | Åšrednie | ğŸ†• Naprawione |
| Brak sanityzacji | Wysokie | ğŸ†• Naprawione |
| Brak CSRF | Åšrednie | ğŸ†• Naprawione |
| Brak offline queue | Niskie | ğŸ†• Naprawione |

---

## âœ… Wykonane Naprawy

### A. Nowy ModuÅ‚ LLM z Ollama i LiteLLM

**Lokalizacja:** `/intentforge/llm/providers.py`

```python
# UÅ¼ycie Ollama (lokalnie)
from intentforge.llm import get_llm_provider

llm = get_llm_provider("ollama", model="llama3")
response = await llm.generate("Create REST API for users")

# UÅ¼ycie LiteLLM (dowolny backend)
llm = get_llm_provider("litellm", model="ollama/codellama")
response = await llm.generate_code("Create MQTT handler")

# Automatyczne wykrywanie z .env
llm = get_llm_provider()  # Czyta LLM_PROVIDER z .env
```

**Wspierane modele:**
- `anthropic` - Claude 3 Opus/Sonnet/Haiku
- `openai` - GPT-4o, GPT-4 Turbo
- `ollama` - llama3, codellama, mistral, phi3
- `litellm` - 100+ modeli przez jeden API

### B. Zunifikowane SDK JavaScript v2.0

**Lokalizacja:** `/frontend/sdk/intentforge.js`

**Nowe funkcje bezpieczeÅ„stwa:**

```javascript
// Rate limiting (60 req/min domyÅ›lnie)
const api = await IntentForge.init({
    enableRateLimit: true,
    rateLimitPerMinute: 60
});

// Walidacja przed wysÅ‚aniem
api.form('contact')
   .rules({
       email: { required: true, type: 'email' },
       message: { required: true, minLength: 10 }
   })
   .submit(data);

// Sanityzacja automatyczna (XSS protection)
// Wszystkie dane sÄ… automatycznie sanityzowane

// CSRF protection
// Token pobierany automatycznie z cookie/API

// Offline queue
const api = await IntentForge.init({
    enableOfflineQueue: true,
    maxQueueSize: 100
});
// Requesty sÄ… kolejkowane gdy offline i wysyÅ‚ane po powrocie online
```

### C. Docker z Ollama i LiteLLM

**Lokalizacja:** `/docker/docker-compose.yml`

```bash
# DomyÅ›lnie (Anthropic API)
docker-compose up -d

# Z lokalnym Ollama
docker-compose --profile ollama up -d
docker exec intentforge-ollama ollama pull llama3

# Z LiteLLM (100+ modeli)
docker-compose --profile litellm up -d

# Wszystko razem
docker-compose --profile full up -d
```

---

## ğŸ“ Nowa Struktura (Zalecana)

```
intentforge/
â”œâ”€â”€ ğŸ“ src/intentforge/              # Kod Python
â”‚   â”œâ”€â”€ llm/                         # ğŸ†• ModuÅ‚ LLM
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ providers.py             # Ollama, LiteLLM, etc.
â”‚   â”œâ”€â”€ services/                    # Serwisy
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“ frontend/                     # ğŸ†• Zunifikowany frontend
â”‚   â”œâ”€â”€ sdk/
â”‚   â”‚   â””â”€â”€ intentforge.js           # SDK v2.0 z security
â”‚   â””â”€â”€ index.html
â”‚
â”œâ”€â”€ ğŸ“ examples/
â”‚   â”œâ”€â”€ python/
â”‚   â””â”€â”€ html/
â”‚
â”œâ”€â”€ ğŸ“ docker/                       # ğŸ†• Docker osobno
â”‚   â”œâ”€â”€ docker-compose.yml           # Z Ollama/LiteLLM
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ mosquitto.conf
â”‚       â”œâ”€â”€ nginx.conf
â”‚       â””â”€â”€ litellm_config.yaml      # ğŸ†• Konfiguracja LiteLLM
â”‚
â”œâ”€â”€ .env.example                     # Jeden plik (usunÄ…Ä‡ duplikat)
â””â”€â”€ pyproject.toml
```

---

## ğŸ”§ Konfiguracja .env dla Ollama/LiteLLM

```env
# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Opcja 1: Anthropic (wymaga klucza API)
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-xxx

# Opcja 2: Ollama (lokalnie, bez klucza)
LLM_PROVIDER=ollama
LLM_MODEL=llama3
OLLAMA_HOST=http://localhost:11434

# Opcja 3: LiteLLM (proxy dla wielu providerÃ³w)
LLM_PROVIDER=litellm
LLM_MODEL=ollama/codellama  # lub gpt-4o, claude-3-sonnet
LITELLM_API_BASE=http://localhost:4000

# Opcja 4: OpenAI
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-xxx
LLM_MODEL=gpt-4o
```

---

## ğŸš€ Szybki Start z Ollama

```bash
# 1. Zainstaluj Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. Pobierz model
ollama pull llama3
ollama pull codellama  # dla generowania kodu

# 3. Skonfiguruj .env
echo "LLM_PROVIDER=ollama" >> .env
echo "LLM_MODEL=llama3" >> .env

# 4. Uruchom IntentForge
docker-compose --profile ollama up -d

# 5. Test
curl http://localhost:8000/api/generate \
  -H "Content-Type: application/json" \
  -d '{"description": "Create REST API for products"}'
```

---

## ğŸ“Š Podsumowanie Zmian

| Komponent | Przed | Po |
|-----------|-------|-----|
| JS SDK | 2 rÃ³Å¼ne pliki | 1 zunifikowany |
| LLM Providers | 2 (Anthropic, OpenAI) | 4+ (+ Ollama, LiteLLM) |
| BezpieczeÅ„stwo Frontend | Brak | Rate limiting, CSRF, Sanityzacja |
| Offline Support | Brak | Queue z localStorage |
| Docker Profiles | 1 | 4 (default, ollama, litellm, full) |
| Walidacja | Server-side tylko | Client + Server |

---

## âš ï¸ Do UsuniÄ™cia (Duplikaty)

1. `/intentforge/static/js/intentforge-client.js` â†’ ZastÄ…piony przez `/frontend/sdk/intentforge.js`
2. `/sdk/intentforge.js` â†’ Przeniesiony do `/frontend/sdk/`
3. `.env.complete.example` â†’ PoÅ‚Ä…czyÄ‡ z `.env.example`
4. `/static/` â†’ PrzenieÅ›Ä‡ do `/frontend/`
